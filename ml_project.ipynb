{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "__Pia CHANCEREL - Raphael LASRY - Maxime POLI__\n",
    "\n",
    "Based on the article :\n",
    "\n",
    "_A Continuation Method for Semi-Supervised SVMs_\n",
    "\n",
    "Olivier Chapelle $\\hspace{3.9cm}$ olivier.chapelle@tuebingen.mpg.de\n",
    "\n",
    "Mingmin Chi $\\hspace{4.5cm}$ mingmin.chi@tuebingen.mpg.de\n",
    "\n",
    "Alexander Zien $\\hspace{4.1cm}$ alexander.zien@tuebingen.mpg.de\n",
    "\n",
    "\n",
    "Max Planck Institute for Biological Cybernetics, Tübingen, Germany\n",
    "\n",
    "https://dl.acm.org/doi/pdf/10.1145/1143844.1143868?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "20newsgroup dataset: https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
    "\n",
    "Dataset of an old forum. We will only focus on messages related to windows and mac. The goal is to predict the subject of the message (windows or mac) thanks to a $S^3VM$ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['comp.sys.mac.hardware', 'comp.os.ms-windows.misc']\n",
    "newsgroups_train = fetch_20newsgroups(subset = 'train', categories = cat) \n",
    "newsgroups_test = fetch_20newsgroups(subset = 'test', categories = cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(newsgroups_train.DESCR) # Documentation of how to use the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "posts (1169,)\n",
      "class (1169,)\n",
      "test set\n",
      "posts (779,)\n",
      "class (779,)\n"
     ]
    }
   ],
   "source": [
    "print('training set')\n",
    "print('posts', newsgroups_train.filenames.shape) # Text, content of the messages\n",
    "print('class', newsgroups_train.target.shape) # In which categories the message should be classified\n",
    "print('test set')\n",
    "print('posts', newsgroups_test.filenames.shape)\n",
    "print('class', newsgroups_test.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169, 48026)\n",
      "(779, 26537)\n"
     ]
    }
   ],
   "source": [
    "# Converting text to vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors_train = vectorizer.fit_transform(newsgroups_train.data) # From a text message to a sparse matrix\n",
    "vectors_test = vectorizer.fit_transform(newsgroups_test.data)\n",
    "print(vectors_train.shape)\n",
    "print(vectors_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11836)\t0.060745952137355695\n",
      "  (0, 24291)\t0.022618106900418693\n",
      "  (0, 41388)\t0.11860995066421275\n",
      "  (0, 31786)\t0.03240293556665717\n",
      "  (0, 29765)\t0.035913087826464844\n",
      "  (0, 39120)\t0.07022124808552059\n",
      "  (0, 16510)\t0.05070982504718354\n",
      "  (0, 35013)\t0.048867754439260905\n",
      "  (0, 24807)\t0.04686961078206869\n",
      "  (0, 20384)\t0.05719755934000299\n",
      "  (0, 41675)\t0.039978081454834856\n",
      "  (0, 11678)\t0.05598156693760046\n",
      "  (0, 22670)\t0.027010341186943107\n",
      "  (0, 26672)\t0.03835102912668531\n",
      "  (0, 46908)\t0.08984813071411515\n",
      "  (0, 24015)\t0.030345755269912806\n",
      "  (0, 9834)\t0.1237192022846886\n",
      "  (0, 15131)\t0.1309202879936192\n",
      "  (0, 21441)\t0.1237192022846886\n",
      "  (0, 27940)\t0.09767696412557507\n",
      "  (0, 16527)\t0.11860995066421275\n",
      "  (0, 16440)\t0.1309202879936192\n",
      "  (0, 955)\t0.07485176283271351\n",
      "  (0, 24739)\t0.04527614649220864\n",
      "  (0, 41399)\t0.05820447219377972\n",
      "  :\t:\n",
      "  (1168, 35408)\t0.06641869967872376\n",
      "  (1168, 37311)\t0.08705716680767477\n",
      "  (1168, 20022)\t0.059099265254513346\n",
      "  (1168, 45316)\t0.07897469031592323\n",
      "  (1168, 1041)\t0.06504179842075553\n",
      "  (1168, 38101)\t0.0971337240247554\n",
      "  (1168, 14550)\t0.030085237190977072\n",
      "  (1168, 32755)\t0.03083291659429828\n",
      "  (1168, 13647)\t0.030392932922562992\n",
      "  (1168, 21610)\t0.03990787188846703\n",
      "  (1168, 44947)\t0.03652896508617383\n",
      "  (1168, 29132)\t0.047015791350209724\n",
      "  (1168, 12372)\t0.07117589502187233\n",
      "  (1168, 11836)\t0.0604081075139186\n",
      "  (1168, 24291)\t0.06747694218269963\n",
      "  (1168, 24807)\t0.023304470402050165\n",
      "  (1168, 41675)\t0.019877869699557772\n",
      "  (1168, 24015)\t0.030176984349360003\n",
      "  (1168, 24739)\t0.022512169361778366\n",
      "  (1168, 41397)\t0.05816525704985521\n",
      "  (1168, 27654)\t0.017706631783382505\n",
      "  (1168, 33842)\t0.018338284642721796\n",
      "  (1168, 33457)\t0.06458092824185795\n",
      "  (1168, 40417)\t0.017661288271258027\n",
      "  (1168, 20868)\t0.017661288271258027\n"
     ]
    }
   ],
   "source": [
    "print(vectors_train) # Sparse matrix. The first index is the index of the message and the second ones are the indexes whithin this matrix where the value isn't a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [2. 2. 2. 2.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.ones((3, 4))\n",
    "Y = np.arange(3)\n",
    "print(np.multiply(X.T, Y).T)\n",
    "(X.T * Y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3VMClassifier():\n",
    "    \"\"\"\n",
    "        S3VM class as defined in the article.\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1.0, C_=1.0, lr=0.01, s=3):\n",
    "        self.C = C\n",
    "        self.C_ = C_\n",
    "        self.lr = lr\n",
    "        self.s = s\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.X_ = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def compute_gamma(self, epochs):\n",
    "        \"\"\"\n",
    "            Compute the list of values of gamma (defined at the §3.2).\n",
    "        \"\"\"\n",
    "        m, d = self.X_.shape\n",
    "        matrix = np.zeros((d, d))\n",
    "        for i in range(m):\n",
    "            matrix += np.outer(self.X_[i], self.X_[i]) / np.linalg.norm(self.X_[i]) ** 3\n",
    "        lamb_max = numpy.linalg.eigh(matrix)[0][- 1]\n",
    "        gamma_0 = (self.C_ * lamb_max) ** (2 / 3) / (2 * self.s) ** (1 / 3)\n",
    "        gamma_end = 1 / (epochs * 2 * self.s * sc.sparse.linalg.norm(self.X_, axis=1).max() ** 2)\n",
    "        gamma_list = [(gamma_end / gamma_0) ** (i / epochs) * gamma_0 for i in range(epochs)]\n",
    "        return gamma_list\n",
    "    \n",
    "    def loss(self, gamma):\n",
    "        \"\"\"\n",
    "            Compute the convolved loss (defined at the end of the §3.1).\n",
    "        \"\"\"\n",
    "        d = self.X.shape[1]\n",
    "        a = 1 + 2 * gamma * self.s * np.linalg.norm(self.X_, axis = 1) ** 2\n",
    "        e = (Y * (self.X.dot(self.w) + self.b) - 1) / np.sqrt(2*gamma) / np.linalg.norm(self.X, axis = 1)\n",
    "        L_labelled = self.C * np.sum(gamma * np.linalg.norm(self.X, axis = 1) / np.sqrt(2) \n",
    "                                     * (np.exp(- e**2) / np.sqrt(np.pi) - e * sc.special.erfc(e)))\n",
    "        L_unlabelled = self.C_ * np.sum(1 / np.sqrt(a) * np.exp(- self.s * (self.X_.dot(self.w) + self.b) ** 2 / a))\n",
    "        return np.dot(self.w, self.w)/2 + gamma*d/2 + L_labelled + L_unlabelled\n",
    "    \n",
    "    def gradient_loss(self, gamma, labelled):\n",
    "        \"\"\"\n",
    "            Compute the gradient of the loss (defined at the end of the §3.1).\n",
    "        \"\"\"\n",
    "        a = 1 + 2 * gamma * self.s * np.linalg.norm(self.X_, axis = 1) ** 2\n",
    "        e = (Y * (self.X.dot(self.w) + self.b) - 1) / np.sqrt(2 * gamma) / np.linalg.norm(self.X, axis = 1)\n",
    "        if labelled:\n",
    "            dL_labelled = self.C / 2 * np.sum(np.multiply(X.T, sc.special.erfc(e) * self.Y).T, axis=0)\n",
    "            return self.w - dL_labelled\n",
    "        else:\n",
    "            dL_unlabelled = self.C_ * np.sum(np.multiply(X.T, 2 * self.s * (self.X_.dot(self.w) + self.b) / a ** (3 / 2)\n",
    "                                         * np.exp(- self.s * (self.X_.dot(self.w) + self.b) ** 2 / a)), axis=0)\n",
    "            return self.w - dL_unlabelled\n",
    "    \n",
    "    def minimize(self, gamma, epochs):\n",
    "        \"\"\"\n",
    "            Optimise the parameters.\n",
    "        \"\"\"\n",
    "        n, d, m = self.X.shape, self.X_.shape[0]\n",
    "        indexes = np.arange(n + m) - m # positive indexes --> labeled & negative indexes --> unlabeled\n",
    "        gw = np.zeros((n + m, d)) # vector of most recent gradient in w\n",
    "        dw = np.zeros(d) # sum of gw\n",
    "        for ep in range(epochs):\n",
    "            np.random.shuffle(indexes)\n",
    "            for k in range(n + m):\n",
    "                i = indexes[k]\n",
    "                labelled = (i >= 0) # labelled or unlabelled\n",
    "                if i < 0 : # if it's the index of an unlabelled data\n",
    "                    i = - i + n # its index is in gw\n",
    "                dw -= gw[i]\n",
    "                gw[i] = self.gradient_loss(gamma, labelled)\n",
    "                dw += gw[i]\n",
    "                self.w -= self.lr / min((k + 1) + ep * (n + m), n + m) * dw\n",
    "    \n",
    "    def fit(self, X, Y, X_, epochs=5, iter_gamma=10): # epochs pour la minimisation, iter_gamma pour le nombre de gamma\n",
    "        \"\"\"\n",
    "            Train the model on X_labelled, Y_labelled, X_unlabelled datas.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.X_ = X_ - np.mean(X_)\n",
    "        \n",
    "        gamma_list = self.compute_gamma(iter_gamma)\n",
    "        # warm start\n",
    "        if (w is None) and (b is None) :\n",
    "            _, d = self.X.shape\n",
    "            self.w = np.zeros(d)\n",
    "            self.b = np.mean(Y)\n",
    "        # continuation method\n",
    "        for gamma in gamma_list :\n",
    "            self.minimize(gamma, epochs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Predict the value of Y (0 or 1).\n",
    "        \"\"\"\n",
    "        return self.w.T.dot(X) + self.b >= 0\n",
    "    \n",
    "    def accuracy(self, X, Y):\n",
    "        \"\"\"\n",
    "            Evaluate the accuracy of the prediction.\n",
    "        \"\"\"\n",
    "        return (self.predict(X) == Y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "subtracting a nonzero scalar from a sparse matrix is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-6ef9edf32d1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ms3vm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mS3VMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ms3vm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvectors_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsgroups_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvectors_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvectors_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms3vm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectors_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewsgroups_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-33-87e7714ab325>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y, X_, epochs, iter_gamma)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mgamma_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_gamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter_gamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m             raise NotImplementedError('subtracting a nonzero scalar from a '\n\u001b[0m\u001b[0;32m    434\u001b[0m                                       'sparse matrix is not supported')\n\u001b[0;32m    435\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: subtracting a nonzero scalar from a sparse matrix is not supported"
     ]
    }
   ],
   "source": [
    "s3vm = S3VMClassifier()\n",
    "s3vm.fit(vectors_train[:int(0.75 * vectors_train.shape[0]), :], newsgroups_train.target[:int(0.75 * vectors_train.shape[0])], vectors_train[int(0.75 * vectors_train.shape[0]):, :])\n",
    "print(s3vm.accuracy(vectors_test, newsgroups_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
