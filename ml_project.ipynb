{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "__Pia CHANCEREL - Raphael LASRY - Maxime POLI__\n",
    "\n",
    "Based on the article :\n",
    "\n",
    "_A Continuation Method for Semi-Supervised SVMs_\n",
    "\n",
    "Olivier Chapelle $\\hspace{3.9cm}$ olivier.chapelle@tuebingen.mpg.de\n",
    "\n",
    "Mingmin Chi $\\hspace{4.5cm}$ mingmin.chi@tuebingen.mpg.de\n",
    "\n",
    "Alexander Zien $\\hspace{4.1cm}$ alexander.zien@tuebingen.mpg.de\n",
    "\n",
    "\n",
    "Max Planck Institute for Biological Cybernetics, Tübingen, Germany\n",
    "\n",
    "https://dl.acm.org/doi/pdf/10.1145/1143844.1143868?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "20newsgroup dataset: https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
    "\n",
    "Dataset of an old forum. We will only focus on messages related to windows and mac. The goal is to predict the subject of the message (windows or mac) thanks to a $S^3VM$ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data['date_int'] = pd.to_datetime(data['date']).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "city = pd.get_dummies(pd.Categorical(data['city']), prefix='city')\n",
    "X_housedata = np.concatenate([data[['date_int', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated']].to_numpy(), city.to_numpy()], axis=1)\n",
    "Y_housedata = data['price'].to_numpy()\n",
    "\n",
    "r = np.random.permutation(len(X_housedata))\n",
    "X_train = X_housedata[r[0:3500], :]\n",
    "Y_train = Y_housedata[r[0:3500]]\n",
    "X_val = X_housedata[r[3500:4000], :]\n",
    "Y_val = Y_housedata[r[3500:4000]]\n",
    "X_test = X_housedata[r[4000:], :]\n",
    "Y_test = Y_housedata[r[4000:]]\n",
    "\n",
    "X_train = (X_train - np.mean(X_train, axis = 0)) / (np.std(X_train, axis = 0) + 10 ** (-15))\n",
    "X_val = (X_val - np.mean(X_val, axis = 0)) / (np.std(X_val, axis = 0) + 10 ** (-15))\n",
    "X_test = (X_test - np.mean(X_test, axis = 0)) / (np.std(X_test, axis = 0) + 10 ** (-15))\n",
    "\n",
    "Y_train = 2 * np.array(np.array(Y_train) - np.median(Y_train) > 0).astype(int) - 1\n",
    "Y_val = 2 * np.array(np.array(Y_val) - np.median(Y_val) > 0).astype(int) - 1\n",
    "Y_test = 2 * np.array(np.array(Y_test) - np.median(Y_test) > 0).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(newsgroups_train.DESCR) # Documentation of how to use the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['comp.sys.mac.hardware', 'comp.os.ms-windows.misc']\n",
    "# cat = ['sci.crypt', 'sci.electronics']\n",
    "newsgroups_train = fetch_20newsgroups(subset = 'train', categories = cat) \n",
    "newsgroups_test = fetch_20newsgroups(subset = 'test', categories = cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('training set')\n",
    "print('posts', newsgroups_train.filenames.shape) # Text, content of the messages\n",
    "print('class', newsgroups_train.target.shape) # In which categories the message should be classified\n",
    "print('test set')\n",
    "print('posts', newsgroups_test.filenames.shape)\n",
    "print('class', newsgroups_test.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting text to vectors\n",
    "vectorizer = TfidfVectorizer(encoding='latin1')\n",
    "# Pas sûr de ma solution mais ça a l'air d'être ça\n",
    "vectorizer.fit(newsgroups_train.data+newsgroups_test.data) # From a text message to a sparse matrix\n",
    "vectors_train = vectorizer.transform(newsgroups_train.data)\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "print(vectors_train.shape)\n",
    "print(vectors_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre moyen de features non nulles\n",
    "vectors_test.nnz/float(vectors_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectors_train) # Sparse matrix. The first index is the index of the message and the second ones are the indexes whithin this matrix where the value isn't a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.ones((3, 4))\n",
    "Y = np.arange(3)\n",
    "print(np.multiply(X.T, Y).T)\n",
    "(X.T * Y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3VMClassifier():\n",
    "    \"\"\"\n",
    "        S3VM class as defined in the article.\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1.0, C_=1.0, lr=0.01, s=3):\n",
    "        self.C = C\n",
    "        self.C_ = C_\n",
    "        self.lr = lr\n",
    "        self.s = s\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.X_ = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def compute_gamma(self, epochs):\n",
    "        \"\"\"\n",
    "            Compute the list of values of gamma (defined at the §3.2).\n",
    "        \"\"\"\n",
    "        m, d = self.X_.shape\n",
    "        matrix = sc.sparse.lil_matrix((d, d))\n",
    "#         matrix = np.zeros((d, d))\n",
    "        for i in range(m):\n",
    "            matrix += self.X_[i].T@self.X_[i] / sc.sparse.linalg.norm(self.X_[i]) ** 3\n",
    "        lamb_max = np.linalg.eigh(matrix)[0][- 1]\n",
    "        gamma_0 = (self.C_ * lamb_max) ** (2 / 3) / (2 * self.s) ** (1 / 3)\n",
    "#         gamma_end = 1 / (epochs * 2 * self.s * sc.sparse.linalg.norm(self.X_, axis=1).max() ** 2)\n",
    "        gamma_end = 1 / (epochs * 2 * self.s * np.linalg.norm(self.X_, axis=1).max() ** 2)\n",
    "        gamma_list = [(gamma_end / gamma_0) ** (i / epochs) * gamma_0 for i in range(epochs)]\n",
    "        return gamma_list\n",
    "    \n",
    "    def loss(self, gamma):\n",
    "        \"\"\"\n",
    "            Compute the convolved loss (defined at the end of the §3.1).\n",
    "        \"\"\"\n",
    "        d = self.X.shape[1]\n",
    "        a = 1 + 2 * gamma * self.s * np.linalg.norm(self.X_, axis = 1) ** 2\n",
    "        e = (self.Y * (self.X.dot(self.w) + self.b) - 1) / np.sqrt(2 * gamma) / np.linalg.norm(self.X, axis = 1)\n",
    "        L_labelled = self.C * np.sum(gamma * np.linalg.norm(self.X, axis = 1) / np.sqrt(2) \n",
    "                                     * (np.exp(- e ** 2) / np.sqrt(np.pi) - e * sc.special.erfc(e)))\n",
    "        L_unlabelled = self.C_ * np.sum(1 / np.sqrt(a) * np.exp(- self.s * (self.X_.dot(self.w) + self.b) ** 2 / a))\n",
    "        return np.dot(self.w, self.w) / 2 + gamma * d / 2 + L_labelled + L_unlabelled\n",
    "    \n",
    "    def gradient_loss(self, gamma, labelled):\n",
    "        \"\"\"\n",
    "            Compute the gradient of the loss (defined at the end of the §3.1).\n",
    "        \"\"\"\n",
    "        a = 1 + 2 * gamma * self.s * np.linalg.norm(self.X_, axis = 1) ** 2\n",
    "        e = (self.Y * (self.X.dot(self.w) + self.b) - 1) / np.sqrt(2 * gamma) / np.linalg.norm(self.X, axis = 1)\n",
    "        if labelled:\n",
    "            dL_labelled = self.C / 2 * np.sum(np.multiply(self.X.T, sc.special.erfc(e) * self.Y).T, axis=0)\n",
    "            return self.w - dL_labelled\n",
    "        else:\n",
    "            dL_unlabelled = self.C_ * np.sum(np.multiply(self.X_.T, 2 * self.s * (self.X_.dot(self.w) + self.b) / a ** (3 / 2)\n",
    "                                         * np.exp(- self.s * (self.X_.dot(self.w) + self.b) ** 2 / a)), axis=1)\n",
    "            return self.w - dL_unlabelled\n",
    "    \n",
    "    def minimize(self, gamma, epochs):\n",
    "        \"\"\"\n",
    "            Optimise the parameters.\n",
    "        \"\"\"\n",
    "        n, d = self.X.shape\n",
    "        m = self.X_.shape[0]\n",
    "        indexes = np.arange(n + m) - m # positive indexes --> labeled & negative indexes --> unlabeled\n",
    "        gw = np.zeros((n + m, d)) # vector of most recent gradient in w\n",
    "        dw = np.zeros(d) # sum of gw\n",
    "        for ep in range(epochs):\n",
    "            np.random.shuffle(indexes)\n",
    "            for k in range(n + m):\n",
    "                i = indexes[k]\n",
    "                labelled = (i >= 0) # labelled or unlabelled\n",
    "                if i < 0 : # if it's the index of an unlabelled data\n",
    "                    i = - i + n - 1 # its index is in gw\n",
    "                dw -= gw[i]\n",
    "                gw[i] = self.gradient_loss(gamma, labelled)\n",
    "                dw += gw[i]\n",
    "                self.w -= self.lr / min((k + 1) + ep * (n + m), n + m) * dw\n",
    "    \n",
    "    def fit(self, X, Y, X_, epochs=3, iter_gamma=5, w=None, b=None): # epochs pour la minimisation, iter_gamma pour le nombre de gamma\n",
    "        \"\"\"\n",
    "            Train the model on X_labelled, Y_labelled, X_unlabelled datas.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        # Centering unlablled data\n",
    "#         values = X_[X_.nonzero()]\n",
    "#         values -= sc.sparse.spmatrix.mean(values, axis = 1)\n",
    "#         self.X_ = values\n",
    "        self.X_ = X_\n",
    "        \n",
    "        gamma_list = self.compute_gamma(iter_gamma)\n",
    "        # warm start\n",
    "        if (w is None) and (b is None) :\n",
    "            _, d = self.X.shape\n",
    "            self.w = np.zeros(d)\n",
    "            self.b = np.mean(Y)\n",
    "        # continuation method\n",
    "        for gamma in tqdm(gamma_list):\n",
    "            self.minimize(gamma, epochs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Predict the value of Y (0 or 1).\n",
    "        \"\"\"\n",
    "        return self.w.T.dot(X.T) + self.b >= 0\n",
    "    \n",
    "    def accuracy(self, X, Y):\n",
    "        \"\"\"\n",
    "            Evaluate the accuracy of the prediction.\n",
    "        \"\"\"\n",
    "        return (self.predict(X) == 1 / 2 * (Y + 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3vm = S3VMClassifier()\n",
    "\n",
    "s3vm.fit(vectors_train[:int(0.75 * vectors_train.shape[0]), :], \n",
    "         newsgroups_train.target[:int(0.75 * vectors_train.shape[0])], \n",
    "         vectors_train[int(0.75 * vectors_train.shape[0]):, :])\n",
    "print(s3vm.accuracy(vectors_test, newsgroups_test))\n",
    "\n",
    "# proportion = 0.5\n",
    "# nb_labelled = int(proportion * X_train.shape[0])\n",
    "# s3vm.fit(X_train[:nb_labelled, :], Y_train[:nb_labelled], X_train[nb_labelled:, :])\n",
    "# print(s3vm.accuracy(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = s3vm.predict(X_test)\n",
    "print(*zip(Y.astype(int), 1 / 2 * (Y_test + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
