{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "__Pia CHANCEREL - Raphael LASRY - Maxime POLI__\n",
    "\n",
    "Based on the article :\n",
    "\n",
    "_A Continuation Method for Semi-Supervised SVMs_\n",
    "\n",
    "Olivier Chapelle $\\hspace{3.9cm}$ olivier.chapelle@tuebingen.mpg.de\n",
    "\n",
    "Mingmin Chi $\\hspace{4.5cm}$ mingmin.chi@tuebingen.mpg.de\n",
    "\n",
    "Alexander Zien $\\hspace{4.1cm}$ alexander.zien@tuebingen.mpg.de\n",
    "\n",
    "\n",
    "Max Planck Institute for Biological Cybernetics, Tübingen, Germany\n",
    "\n",
    "https://dl.acm.org/doi/pdf/10.1145/1143844.1143868?download=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "20newsgroup dataset: https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
    "\n",
    "Dataset of an old forum. We will only focus on messages related to windows and mac. The goal is to predict the subject of the message (windows or mac) thanks to a $S^3VM$ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['comp.sys.mac.hardware', 'comp.os.ms-windows.misc']\n",
    "newsgroups_train = fetch_20newsgroups(subset = 'train', categories = cat) \n",
    "newsgroups_test = fetch_20newsgroups(subset = 'test', categories = cat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data['date_int'] = pd.to_datetime(data['date']).dt.strftime(\"%Y%m%d\").astype(int)\n",
    "city = pd.get_dummies(pd.Categorical(data['city']), prefix='city')\n",
    "X_housedata = np.concatenate([data[['date_int', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated']].to_numpy(), city.to_numpy()], axis=1)\n",
    "Y_housedata = data['price'].to_numpy()\n",
    "\n",
    "r = np.random.permutation(len(X_housedata))\n",
    "X_train = X_housedata[r[0:3500], :]\n",
    "Y_train = Y_housedata[r[0:3500]]\n",
    "X_val = X_housedata[r[3500:4000], :]\n",
    "Y_val = Y_housedata[r[3500:4000]]\n",
    "X_test = X_housedata[r[4000:], :]\n",
    "Y_test = Y_housedata[r[4000:]]\n",
    "\n",
    "X_train = (X_train - np.mean(X_train, axis = 0)) / (np.std(X_train, axis = 0) + 10 ** (-15))\n",
    "X_val = (X_val - np.mean(X_val, axis = 0)) / (np.std(X_val, axis = 0) + 10 ** (-15))\n",
    "X_test = (X_test - np.mean(X_test, axis = 0)) / (np.std(X_test, axis = 0) + 10 ** (-15))\n",
    "\n",
    "Y_train = 2 * np.array(np.array(Y_train) - np.median(Y_train) > 0).astype(int) - 1\n",
    "Y_val = 2 * np.array(np.array(Y_val) - np.median(Y_val) > 0).astype(int) - 1\n",
    "Y_test = 2 * np.array(np.array(Y_test) - np.median(Y_test) > 0).astype(int) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(newsgroups_train.DESCR) # Documentation of how to use the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set\n",
      "posts (1169,)\n",
      "class (1169,)\n",
      "test set\n",
      "posts (779,)\n",
      "class (779,)\n"
     ]
    }
   ],
   "source": [
    "print('training set')\n",
    "print('posts', newsgroups_train.filenames.shape) # Text, content of the messages\n",
    "print('class', newsgroups_train.target.shape) # In which categories the message should be classified\n",
    "print('test set')\n",
    "print('posts', newsgroups_test.filenames.shape)\n",
    "print('class', newsgroups_test.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1169, 48026)\n",
      "(779, 26537)\n"
     ]
    }
   ],
   "source": [
    "# Converting text to vectors\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors_train = vectorizer.fit_transform(newsgroups_train.data) # From a text message to a sparse matrix\n",
    "vectors_test = vectorizer.fit_transform(newsgroups_test.data)\n",
    "print(vectors_train.shape)\n",
    "print(vectors_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 11836)\t0.060745952137355695\n",
      "  (0, 24291)\t0.022618106900418693\n",
      "  (0, 41388)\t0.11860995066421275\n",
      "  (0, 31786)\t0.03240293556665717\n",
      "  (0, 29765)\t0.035913087826464844\n",
      "  (0, 39120)\t0.07022124808552059\n",
      "  (0, 16510)\t0.05070982504718354\n",
      "  (0, 35013)\t0.048867754439260905\n",
      "  (0, 24807)\t0.04686961078206869\n",
      "  (0, 20384)\t0.05719755934000299\n",
      "  (0, 41675)\t0.039978081454834856\n",
      "  (0, 11678)\t0.05598156693760046\n",
      "  (0, 22670)\t0.027010341186943107\n",
      "  (0, 26672)\t0.03835102912668531\n",
      "  (0, 46908)\t0.08984813071411515\n",
      "  (0, 24015)\t0.030345755269912806\n",
      "  (0, 9834)\t0.1237192022846886\n",
      "  (0, 15131)\t0.1309202879936192\n",
      "  (0, 21441)\t0.1237192022846886\n",
      "  (0, 27940)\t0.09767696412557507\n",
      "  (0, 16527)\t0.11860995066421275\n",
      "  (0, 16440)\t0.1309202879936192\n",
      "  (0, 955)\t0.07485176283271351\n",
      "  (0, 24739)\t0.04527614649220864\n",
      "  (0, 41399)\t0.05820447219377972\n",
      "  :\t:\n",
      "  (1168, 35408)\t0.06641869967872376\n",
      "  (1168, 37311)\t0.08705716680767477\n",
      "  (1168, 20022)\t0.059099265254513346\n",
      "  (1168, 45316)\t0.07897469031592323\n",
      "  (1168, 1041)\t0.06504179842075553\n",
      "  (1168, 38101)\t0.0971337240247554\n",
      "  (1168, 14550)\t0.030085237190977072\n",
      "  (1168, 32755)\t0.03083291659429828\n",
      "  (1168, 13647)\t0.030392932922562992\n",
      "  (1168, 21610)\t0.03990787188846703\n",
      "  (1168, 44947)\t0.03652896508617383\n",
      "  (1168, 29132)\t0.047015791350209724\n",
      "  (1168, 12372)\t0.07117589502187233\n",
      "  (1168, 11836)\t0.0604081075139186\n",
      "  (1168, 24291)\t0.06747694218269963\n",
      "  (1168, 24807)\t0.023304470402050165\n",
      "  (1168, 41675)\t0.019877869699557772\n",
      "  (1168, 24015)\t0.030176984349360003\n",
      "  (1168, 24739)\t0.022512169361778366\n",
      "  (1168, 41397)\t0.05816525704985521\n",
      "  (1168, 27654)\t0.017706631783382505\n",
      "  (1168, 33842)\t0.018338284642721796\n",
      "  (1168, 33457)\t0.06458092824185795\n",
      "  (1168, 40417)\t0.017661288271258027\n",
      "  (1168, 20868)\t0.017661288271258027\n"
     ]
    }
   ],
   "source": [
    "print(vectors_train) # Sparse matrix. The first index is the index of the message and the second ones are the indexes whithin this matrix where the value isn't a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [2. 2. 2. 2.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.ones((3, 4))\n",
    "Y = np.arange(3)\n",
    "print(np.multiply(X.T, Y).T)\n",
    "(X.T * Y).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3VMClassifier():\n",
    "    \"\"\"\n",
    "        S3VM class as defined in the article.\n",
    "    \"\"\"\n",
    "    def __init__(self, C=1.0, C_=1.0, lr=0.01, s=3):\n",
    "        self.C = C\n",
    "        self.C_ = C_\n",
    "        self.lr = lr\n",
    "        self.s = s\n",
    "        self.X = None\n",
    "        self.Y = None\n",
    "        self.X_ = None\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        \n",
    "    def compute_gamma(self, epochs):\n",
    "        \"\"\"\n",
    "            Compute the list of values of gamma (defined at the §3.2).\n",
    "        \"\"\"\n",
    "        m, d = self.X_.shape\n",
    "#         matrix = sc.sparse.lil_matrix((d, d))\n",
    "        matrix = np.zeros((d, d))\n",
    "        for i in range(m):\n",
    "            matrix += self.X_[i].T@self.X_[i] / np.linalg.norm(self.X_[i]) ** 3\n",
    "        lamb_max = np.linalg.eigh(matrix)[0][- 1]\n",
    "        gamma_0 = (self.C_ * lamb_max) ** (2 / 3) / (2 * self.s) ** (1 / 3)\n",
    "#         gamma_end = 1 / (epochs * 2 * self.s * sc.sparse.linalg.norm(self.X_, axis=1).max() ** 2)\n",
    "        gamma_end = 1 / (epochs * 2 * self.s * np.linalg.norm(self.X_, axis=1).max() ** 2)\n",
    "        gamma_list = [(gamma_end / gamma_0) ** (i / epochs) * gamma_0 for i in range(epochs)]\n",
    "        return gamma_list\n",
    "    \n",
    "    def loss(self, gamma):\n",
    "        \"\"\"\n",
    "            Compute the convolved loss (defined at the end of the §3.1).\n",
    "        \"\"\"\n",
    "        d = self.X.shape[1]\n",
    "        a = 1 + 2 * gamma * self.s * np.linalg.norm(self.X_, axis = 1) ** 2\n",
    "        e = (self.Y * (self.X.dot(self.w) + self.b) - 1) / np.sqrt(2 * gamma) / np.linalg.norm(self.X, axis = 1)\n",
    "        L_labelled = self.C * np.sum(gamma * np.linalg.norm(self.X, axis = 1) / np.sqrt(2) \n",
    "                                     * (np.exp(- e ** 2) / np.sqrt(np.pi) - e * sc.special.erfc(e)))\n",
    "        L_unlabelled = self.C_ * np.sum(1 / np.sqrt(a) * np.exp(- self.s * (self.X_.dot(self.w) + self.b) ** 2 / a))\n",
    "        return np.dot(self.w, self.w) / 2 + gamma * d / 2 + L_labelled + L_unlabelled\n",
    "    \n",
    "    def gradient_loss(self, gamma, labelled):\n",
    "        \"\"\"\n",
    "            Compute the gradient of the loss (defined at the end of the §3.1).\n",
    "        \"\"\"\n",
    "        a = 1 + 2 * gamma * self.s * np.linalg.norm(self.X_, axis = 1) ** 2\n",
    "        e = (self.Y * (self.X.dot(self.w) + self.b) - 1) / np.sqrt(2 * gamma) / np.linalg.norm(self.X, axis = 1)\n",
    "        if labelled:\n",
    "            dL_labelled = self.C / 2 * np.sum(np.multiply(self.X.T, sc.special.erfc(e) * self.Y).T, axis=0)\n",
    "            return self.w - dL_labelled\n",
    "        else:\n",
    "            dL_unlabelled = self.C_ * np.sum(np.multiply(self.X_.T, 2 * self.s * (self.X_.dot(self.w) + self.b) / a ** (3 / 2)\n",
    "                                         * np.exp(- self.s * (self.X_.dot(self.w) + self.b) ** 2 / a)), axis=1)\n",
    "            return self.w - dL_unlabelled\n",
    "    \n",
    "    def minimize(self, gamma, epochs):\n",
    "        \"\"\"\n",
    "            Optimise the parameters.\n",
    "        \"\"\"\n",
    "        n, d = self.X.shape\n",
    "        m = self.X_.shape[0]\n",
    "        indexes = np.arange(n + m) - m # positive indexes --> labeled & negative indexes --> unlabeled\n",
    "        gw = np.zeros((n + m, d)) # vector of most recent gradient in w\n",
    "        dw = np.zeros(d) # sum of gw\n",
    "        for ep in range(epochs):\n",
    "            np.random.shuffle(indexes)\n",
    "            for k in range(n + m):\n",
    "                i = indexes[k]\n",
    "                labelled = (i >= 0) # labelled or unlabelled\n",
    "                if i < 0 : # if it's the index of an unlabelled data\n",
    "                    i = - i + n - 1 # its index is in gw\n",
    "                dw -= gw[i]\n",
    "                gw[i] = self.gradient_loss(gamma, labelled)\n",
    "                dw += gw[i]\n",
    "                self.w -= self.lr / min((k + 1) + ep * (n + m), n + m) * dw\n",
    "    \n",
    "    def fit(self, X, Y, X_, epochs=3, iter_gamma=5, w=None, b=None): # epochs pour la minimisation, iter_gamma pour le nombre de gamma\n",
    "        \"\"\"\n",
    "            Train the model on X_labelled, Y_labelled, X_unlabelled datas.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        # Centering unlablled data\n",
    "#         values = X_[X_.nonzero()]\n",
    "#         values -= sc.sparse.spmatrix.mean(values, axis = 1)\n",
    "#         self.X_ = values\n",
    "        self.X_ = X_\n",
    "        \n",
    "        gamma_list = self.compute_gamma(iter_gamma)\n",
    "        # warm start\n",
    "        if (w is None) and (b is None) :\n",
    "            _, d = self.X.shape\n",
    "            self.w = np.zeros(d)\n",
    "            self.b = np.mean(Y)\n",
    "        # continuation method\n",
    "        for gamma in tqdm(gamma_list):\n",
    "            self.minimize(gamma, epochs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "            Predict the value of Y (0 or 1).\n",
    "        \"\"\"\n",
    "        return self.w.T.dot(X.T) + self.b >= 0\n",
    "    \n",
    "    def accuracy(self, X, Y):\n",
    "        \"\"\"\n",
    "            Evaluate the accuracy of the prediction.\n",
    "        \"\"\"\n",
    "        return (self.predict(X) == 1 / 2 * (Y + 1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:19<00:00, 39.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7716666666666666\n"
     ]
    }
   ],
   "source": [
    "s3vm = S3VMClassifier()\n",
    "# s3vm.fit(vectors_train[:int(0.75 * vectors_train.shape[0]), :], newsgroups_train.target[:int(0.75 * vectors_train.shape[0])], vectors_train[int(0.75 * vectors_train.shape[0]):, :])\n",
    "# print(s3vm.accuracy(vectors_test, newsgroups_test))\n",
    "s3vm.fit(X_train[:int(0.75 * X_train.shape[0]), :], Y_train[:int(0.75 * X_train.shape[0])], X_train[int(0.75 * X_train.shape[0]):, :])\n",
    "print(s3vm.accuracy(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.0) (0, 0.0) (1, 0.0) (1, 1.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 0.0) (0, 0.0) (1, 1.0) (1, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 1.0) (1, 0.0) (0, 0.0) (0, 0.0) (1, 0.0) (0, 0.0) (0, 1.0) (1, 1.0) (0, 1.0) (1, 1.0) (0, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 0.0) (1, 0.0) (0, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 0.0) (0, 0.0) (1, 1.0) (1, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (1, 1.0) (1, 0.0) (0, 1.0) (1, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 1.0) (0, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 1.0) (1, 1.0) (1, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 0.0) (1, 1.0) (1, 0.0) (0, 1.0) (0, 1.0) (0, 0.0) (1, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 0.0) (1, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 0.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 1.0) (1, 1.0) (1, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 1.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 1.0) (0, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 1.0) (0, 1.0) (1, 1.0) (0, 1.0) (1, 1.0) (1, 0.0) (1, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 1.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 0.0) (0, 1.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 1.0) (0, 0.0) (1, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 0.0) (1, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 1.0) (1, 1.0) (1, 1.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 0.0) (0, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 0.0) (0, 1.0) (0, 0.0) (0, 0.0) (0, 1.0) (0, 0.0) (0, 1.0) (0, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (0, 0.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 1.0) (0, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 1.0) (0, 0.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 0.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 0.0) (0, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 0.0) (0, 1.0) (1, 0.0) (0, 0.0) (0, 1.0) (1, 1.0) (0, 1.0) (0, 1.0) (1, 1.0) (1, 1.0) (0, 1.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 0.0) (1, 1.0) (0, 1.0) (0, 0.0) (0, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (0, 1.0) (1, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (1, 0.0) (0, 1.0) (1, 0.0) (0, 0.0) (1, 0.0) (1, 1.0) (1, 1.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 0.0) (1, 1.0) (1, 1.0) (0, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 1.0) (0, 1.0) (1, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 0.0) (1, 0.0) (1, 1.0) (0, 0.0) (0, 1.0) (0, 0.0) (0, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (0, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 1.0) (1, 0.0) (1, 1.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 0.0) (0, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (1, 1.0) (0, 0.0) (1, 0.0) (1, 1.0)\n"
     ]
    }
   ],
   "source": [
    "Y = s3vm.predict(X_test)\n",
    "print(*zip(Y.astype(int), 1 / 2 * (Y_test + 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
